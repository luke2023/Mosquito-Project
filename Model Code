import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
import statsmodels.api as sm
from statsmodels.tsa.tsatools import lagmat
import matplotlib.pyplot as plt

# Load the data
file_path = 'Data.xlsx'
df = pd.read_excel(file_path)

# Assuming 'precip' is the target variable and others are features
features = df[['humidity', 'temp', 'solarradiation', 'cloudcover']]
target = df['precip']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

# Reshape data for LSTM [samples, timesteps, features]
X_train_lstm = np.expand_dims(X_train, axis=1)
X_test_lstm = np.expand_dims(X_test, axis=1)

# Define the LSTM model
model_lstm = Sequential()
model_lstm.add(LSTM(100, activation='relu', input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))
model_lstm.add(Dense(1))
model_lstm.compile(optimizer='adam', loss='mse')

# Train the LSTM model
model_lstm.fit(X_train_lstm, y_train, epochs=100, batch_size=32, validation_data=(X_test_lstm, y_test), verbose=1)

# Extract features from LSTM model
train_features_lstm = model_lstm.predict(X_train_lstm)
test_features_lstm = model_lstm.predict(X_test_lstm)

# Reshape the features for PDL model
train_features_lstm = train_features_lstm.reshape(-1, 1)
test_features_lstm = test_features_lstm.reshape(-1, 1)

# Combine LSTM features with original features for PDL model
X_train_pdl = np.concatenate((X_train, train_features_lstm), axis=1)
X_test_pdl = np.concatenate((X_test, test_features_lstm), axis=1)

# Adding a constant to the model for intercept
X_train_pdl = sm.add_constant(X_train_pdl)
X_test_pdl = sm.add_constant(X_test_pdl)

# Create lagged features for the PDL model
max_lag = 1
lagged_train_features = lagmat(X_train_pdl, max_lag, trim='both')
lagged_test_features = lagmat(X_test_pdl, max_lag, trim='both')

# Fit the PDL model using statsmodels
model_pdl = sm.OLS(y_train[max_lag:], lagged_train_features).fit()

# Predict using the PDL model
y_pred_pdl = model_pdl.predict(lagged_test_features)

# Evaluate the PDL model
mae_pdl = mean_absolute_error(y_test[max_lag:], y_pred_pdl)
rmse_pdl = np.sqrt(mean_squared_error(y_test[max_lag:], y_pred_pdl))
r2_pdl = r2_score(y_test[max_lag:], y_pred_pdl)

print(f'PDL Model - Mean Absolute Error: {mae_pdl}')
print(f'PDL Model - Root Mean Squared Error: {rmse_pdl}')
print(f'PDL Model - R-squared: {r2_pdl}')

# Plot the actual vs predicted values for PDL model
plt.figure(figsize=(10, 6))
plt.plot(y_test[max_lag:].values, label='Actual', marker='o')
plt.plot(y_pred_pdl, label='Predicted', marker='x')
plt.title('Actual vs Predicted Values (PDL Model)')
plt.xlabel('Samples')
plt.ylabel('Precipitation')
plt.legend()
plt.show()

# Predict using the LSTM model
y_pred_lstm = model_lstm.predict(X_test_lstm)
mae_lstm = mean_absolute_error(y_test, y_pred_lstm)
rmse_lstm = np.sqrt(mean_squared_error(y_test, y_pred_lstm))
r2_lstm = r2_score(y_test, y_pred_lstm)

print(f'LSTM Model - Mean Absolute Error: {mae_lstm}')
print(f'LSTM Model - Root Mean Squared Error: {rmse_lstm}')
print(f'LSTM Model - R-squared: {r2_lstm}')

# Plot the actual vs predicted values for LSTM model
plt.figure(figsize=(10, 6))
plt.plot(y_test.values, label='Actual', marker='o')
plt.plot(y_pred_lstm, label='Predicted', marker='x')
plt.title('Actual vs Predicted Values (LSTM Model)')
plt.xlabel('Samples')
plt.ylabel('Precipitation')
plt.legend()
plt.show()
